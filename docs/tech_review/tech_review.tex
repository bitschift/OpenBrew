zdocumentclass[draftclsnofoot,onecolumn,letterpaper,10pt]{IEEEtran}
\pagestyle{empty}
\usepackage{geometry}
\geometry{textheight=9.5in, textwidth=7in}

\newcommand{\subparagraph}{}
\usepackage{titlesec}

\titleformat{\section}[block]{\bfseries\Large}{\thesection}{0.4em}{}
\titleformat{\subsection}[block]{\bfseries\large}{\thesubsection}{0.4em}{}
\titleformat{\subsubsection}[block]{\bfseries\normalsize}{\thesubsubsection}{0.4em}{}
\setlength{\parindent}{0pt}
\renewcommand{\thesection}{\arabic{section}}
\renewcommand{\thesubsection}{\thesection.\arabic{subsection}}
\renewcommand{\thesubsubsection}{\thesubsection.\arabic{subsubsection}}


\author{Connor Yates\\
\texttt{yatesco@oregonstate.edu\\}
\and
Aravind Parasurama\\
\texttt{parasura@oregonstate.edu\\}
\and
Cody Holliday\\
\texttt{hollidac@oregonstate.edu\\}}
\date{\today}
\title{brew.ai Client Requirements}
\begin{document}
\maketitle

\newpage
\tableofcontents
\newpage
\section{Overview}
This document provides a technical review of three broad topics within the brew.ai project: hardware, user interface, and machine learning.
Each broad topic will be discussed in its own section, preceded by an introduction by the section author.
After the introduction, a review of the potential technologies will be given.
Each broad topic will be divvied into three or more sub-topics, which will address specific technologies that will be combined to address the broad topic of the section.
Finally, each broad topic will have a recommendation about which specific technologies should be used.

\section{Controller Hardware}

\section{User Interface}

\section{Machine Learning \\ -- \textbf{\textit{Connor Yates}}}
\subsection{Introduction}
While a vague title, this section investigates one of the defining features of brew.ai.
In order to create an automated brewing system that not only controls the process in an automated fashion, but can learn from mistakes and improve upon the product, a method of artificial intelligence must be used.
The artificial intelligence that must be imbued in the project has the specific goal of controlling the brewing process.
This is done by sending high level signals such as ``raise temperature'' or ``reduce stir rate'' to the hardware motor controller discussed in Aravind's section.
In order to make these decisions, a continual stream of data from the sensors is fed into the artificial intelligence module, which inform the decision.
Learning will be done in a ``online'' manner, since this allows improvements to the controller policy to happen in between batches \cite{RussellNorvig}.

There are several parts to the artificial intelligence setup for the brew.ai project.
This section will focus on three main aspects: learning algorithm, decision making structure, and preexisting implementations.
It is important to note that these aspects are not mutually exclusive. 
Decisions made in one section may effect the choices in another section.
However, there is still a large degree of freedom between each section, especially with regards to the preexisting software packages that are available.

\subsection{Learning Algorithm}
The class of learning algorithm used is a major choice when setting up the machine learning aspect of the project.
This will dictate how the controller policy will behave while we try to feed it data, which is the most complex part of the machine learning subsection.
\subsubsection{Q-Learning}
Q-learning is a traditional reinforcement learning technique where all possible states and actions are paired up, and a reward mapping between the current state and potential actions can be learned and exploited \cite{SuttonBarto}.
This method is based off a dynamic programming representation of learning, where knowledge from nearby states gets combined into the final value of the state-action pair.
This is important because it creates a solid method of temporal-difference learning \cite{SuttonBarto}, as it becomes possible to associate rewards to series of actions.
As more chains of actions are taken, it can become clear to the agent which actions are preferable in which states.
By learning the action-value function, which returns the most favorable reward at a given state, the agent learns to act optimally within the world.
\subsubsection{Bayesian Modeling with Model Averaging}
Based on the standard Bayesian probabilistic equations, Bayesian modeling uses Bayesian networks as a framework for learning \cite{RussellNorvig}.

While there are different approaches in which Bayesian modeling can be used, the most applicable to our domain is the application known as structure learning \cite{RussellNorvig}.
In this method, machine learning techniques are used to determine the structure of the Bayesian network which best represents the data.

With smaller data sets, such as what I anticipate with this project, a method can be used for Bayesian modeling where multiple models are produced with various dimensionality requirements, and then averaged to create a single model \cite{RussellNorvig}
This allows us to create a better fitting model without needing large amounts of data like other methods would require.

\subsubsection{Deep Learning}
Deep learning is a popular subject in today's media, with the success of projects like AlphaGo grabbing headlines \cite{alphago}.
Conceptually, deep learning focuses on leveraging smart methods of analyzing data to extract high level abstractions and features within complex data sets \cite{Goodfellow-et-al-2016-Book}.
While the technology behind deep learning is impressive, it heavily relies on utilizing massive datasets in order to learn complex, obscure patterns.
This is fundamentally impossible with our project, since we do not have the time nor budget to spend a year gathering data.

\subsubsection{Genetic Algorithms}
Genetic algorithms look at creating powerful solutions to problems by leveraging biologically-inspired techniques \cite{RussellNorvig}.
The concepts of mutation, selection, and genetic crossover have been successfully applied to a variety of state-search problems in the past \cite{RussellNorvig}.
Agent policies, which govern their actions, can be represented as numerical arrays.
The specific transformation for this depends on the model used (ie, neural networks vs state tables).
In either case, genetic algorithms use a population of agent policies which all run and receive a reward.
These rewards are used to calculate the fitness of an policy, which determines how likely the policy is to create offspring and continue to exist \cite{RussellNorvig}.
At the end of each generation of policy performance, the rewards are assigned, fitness is determined, and the creation of new policies begins.
This method is generally modeled after biological reproduction, and can use concepts such as genome crossover and genetic mutation to create new policies to be evaluated.

\subsection{Decision Making Structure}
Some of these methods presented are heavily tied to a specific type of learning algorithm, eg Bayesian networks are mostly only of use when paired with Bayesian models.
However, the differences between these types of structures helps define the state space the learner will operate over.
For example, a neural network can be used as a continuous approximate of a Q-table in continuous reinforcement learning domains.
The decisions present in this section will shape how the problem domain is modeled.

\subsubsection{Neural Networks}
Neural networks are a computational equivalent to neurons within human brains \cite{SuttonBarto}.
The network is made from a series of individual neurons, which are connected in layers.
An individual neuron can be though of as a single linear function: it receives an input signal, applies some weighting and bias, and creates an output signal.
The individual neuron is not incredibly powerful, but when combined in series, they gain the ability to create complex function approximates \cite{SuttonBarto}.

When the weights to individual neurons are set correctly, the connected series of neurons can approximate complex phenomena that would be near impossible to model by hand.
This is one of the major appeals to using neural networks for machine learning tasks.
Additionally, neurons typically receive floating point numbers as input, which does not limit them to discrete domains.
As networks are built, there is no theoretical limit to the number of input or output signals.
This is useful as it allows the network to easily receive each sensor as an input, and send signals to each actuator as output.

\subsubsection{State-Action Table}
State-action tables are a simple method of determine what actions to take.
Simply put, the agent looks at what state it is in - the status of all the information the sensors can provide to the agent.
This state is used as a key which is looked up in the table, where an action is read out.
This action is then acted upon by the agent, and the cycle begins again with sensing.

One issue with this method is that the entire table has to be stored by the agent at all times.
It does not have to be actively loaded into memory constantly, but the table quickly takes up room as the dimensionality of the state grows.
This makes the state-action table representation ill-suited to high-dimensional problems.
However, while this makes this solution infeasible in high-dimensional problems, it creates a strong case for smaller-dimensional problems.
Lookup tables are incredibly quick to access and edit, which allows the agent to have speedy response times in both learning and acting phases.

\subsubsection{Bayesian Networks}
Bayesian networks are directed graphs which represent a probabilistic hierarchy of information \cite{RussellNorvig}.
They allow us to mathematically represent dependencies between fields of information.
For example, the question ``Is it warm in the house?'' is dependent upon the answers to ``Is it summer?'' and ``Do the tenants have a heater?''.
Depending on the status of the answers to the latter questions, we can make a more informed decision about the status of warmth in the house.

Within the context of our problem, a Bayesian network provides the ability to take current sensor readings, and use those to populate a probability table which represents our system.
The dimensionality of that table is determined by the expert in the system (myself, in our case) but the Bayesian network provides the structure on how to fill out the table.
This table is then used to calculate desired probabilities about how much impact given actions would have on the system, which would give us the necessary information to make a decision about the next action to take.

\subsection{Preexisting Implementations}
This section looks at pre-implemented libraries that are available for machine learning routines.
Considerations on memory usage, programming language API, and available functionality are the primary concerns for this sections.
\subsubsection{Keras}
Keras is a high level machine learning suite built for the Python programming language.
\subsubsection{FANN}
\subsubsection{Torch}

\subsection{Recommendation}
\subsubsection{Learning Algorithm}
\subsubsection{Decision Making Structure}
\subsubsection{Preexisting Implementation}


\newpage
\bibliography{tech_review}
\bibliographystyle{ieeetr}


\end{document}
